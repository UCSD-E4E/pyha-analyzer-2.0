{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8149ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c153dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyha_analyzer import PyhaTrainer, extractors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20fab9",
   "metadata": {},
   "source": [
    "# Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eadc0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorry TQ, I don't have these files mounted yet...\n",
    "# peru132_extr = extractors.Peru132Extractor()\n",
    "# peru_132_ads = peru132_extr(\"/data/XC_wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8862a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peru_132_ads = peru_132_ads.get_provenance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91dfeaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'filepath', 'start_time', 'end_time', 'low_freq', 'high_freq', 'ebird_code', 'ebird_code_multilabel', 'ebird_code_secondary', 'call_type', 'sex', 'lat', 'long', 'length', 'microphone', 'license', 'source', 'local_time', 'detected_events', 'event_cluster', 'peaks', 'quality', 'recordist', 'genus', 'species_group', 'order', 'genus_multilabel', 'species_group_multilabel', 'order_multilabel', 'audio_in', 'labels'],\n",
       "        num_rows: 4368\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['audio', 'filepath', 'start_time', 'end_time', 'low_freq', 'high_freq', 'ebird_code', 'ebird_code_multilabel', 'ebird_code_secondary', 'call_type', 'sex', 'lat', 'long', 'length', 'microphone', 'license', 'source', 'local_time', 'detected_events', 'event_cluster', 'peaks', 'quality', 'recordist', 'genus', 'species_group', 'order', 'genus_multilabel', 'species_group_multilabel', 'order_multilabel', 'audio_in', 'labels'],\n",
       "        num_rows: 1092\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'filepath', 'start_time', 'end_time', 'low_freq', 'high_freq', 'ebird_code', 'ebird_code_multilabel', 'ebird_code_secondary', 'call_type', 'sex', 'lat', 'long', 'length', 'microphone', 'license', 'source', 'local_time', 'detected_events', 'event_cluster', 'peaks', 'quality', 'recordist', 'genus', 'species_group', 'order', 'genus_multilabel', 'species_group_multilabel', 'order_multilabel', 'audio_in', 'labels'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birdset_extactor = extractors.Birdset()\n",
    "\n",
    "hsn_ads = birdset_extactor(\"HSN\")\n",
    "# per_ads = birdset_extactor(\"PER\")\n",
    "\n",
    "hsn_ads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa44f245",
   "metadata": {},
   "source": [
    "# Online Preprocessing example\n",
    "\n",
    "Suppose we just wanted spectrograms with no audio preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "799ff026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bytes': None,\n",
       " 'path': '/home/s.perry.543/.cache/huggingface/datasets/downloads/extracted/e7a5318118cabfab47a509edeb627860a60537535aeea20a19fced4c110d579e/HSN_001_20150708_061805_000_005.ogg'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsn_ads[\"test\"][0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe2c636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'filepath', 'start_time', 'end_time', 'low_freq', 'high_freq', 'ebird_code', 'ebird_code_multilabel', 'ebird_code_secondary', 'call_type', 'sex', 'lat', 'long', 'length', 'microphone', 'license', 'source', 'local_time', 'detected_events', 'event_cluster', 'peaks', 'quality', 'recordist', 'genus', 'species_group', 'order', 'genus_multilabel', 'species_group_multilabel', 'order_multilabel', 'audio_in', 'labels'],\n",
       "        num_rows: 4368\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['audio', 'filepath', 'start_time', 'end_time', 'low_freq', 'high_freq', 'ebird_code', 'ebird_code_multilabel', 'ebird_code_secondary', 'call_type', 'sex', 'lat', 'long', 'length', 'microphone', 'license', 'source', 'local_time', 'detected_events', 'event_cluster', 'peaks', 'quality', 'recordist', 'genus', 'species_group', 'order', 'genus_multilabel', 'species_group_multilabel', 'order_multilabel', 'audio_in', 'labels'],\n",
       "        num_rows: 1092\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'filepath', 'start_time', 'end_time', 'low_freq', 'high_freq', 'ebird_code', 'ebird_code_multilabel', 'ebird_code_secondary', 'call_type', 'sex', 'lat', 'long', 'length', 'microphone', 'license', 'source', 'local_time', 'detected_events', 'event_cluster', 'peaks', 'quality', 'recordist', 'genus', 'species_group', 'order', 'genus_multilabel', 'species_group_multilabel', 'order_multilabel', 'audio_in', 'labels'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsn_ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835d7239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "      shape=(1, 128, 216), dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyha_analyzer.preprocessors import MelSpectrogramPreprocessors\n",
    "\n",
    "# preprocessor acts as a function for processing\n",
    "# class allows us to configure parameters and whatnot\n",
    "preprocessor = MelSpectrogramPreprocessors(duration=5)\n",
    "\n",
    "hsn_ads.set_transform(preprocessor)\n",
    "hsn_ads[\"train\"][[0, 1]][\"audio\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d27af",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "As a demo, implementing a model here because we haven't fleshed out the AudioDataset api yet\n",
    "\n",
    "In the future this exists in `/pyha_analyzer/models/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e83ab7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyha_analyzer.models.demo_CNN import ResnetConfig, ResnetModel\n",
    "\n",
    "# Going to make notes on anything that should be handled not here\n",
    "# This is one of these things, this should be handled by potentially pyha_trainer\n",
    "resnet50d_config = ResnetConfig(\n",
    "    num_classes=len(hsn_ads[\"train\"].features[\"ebird_code\"].names), input_channels=1\n",
    ")\n",
    "model = ResnetModel(resnet50d_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1424f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshperry\u001b[0m (\u001b[33macoustic-species-identification\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/s.perry.543/pyha-analyzer-2.0/wandb/run-20250508_150828-dh99x6il</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/acoustic-species-identification/pa2.0_test/runs/dh99x6il' target=\"_blank\">working_dir</a></strong> to <a href='https://wandb.ai/acoustic-species-identification/pa2.0_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/acoustic-species-identification/pa2.0_test' target=\"_blank\">https://wandb.ai/acoustic-species-identification/pa2.0_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/acoustic-species-identification/pa2.0_test/runs/dh99x6il' target=\"_blank\">https://wandb.ai/acoustic-species-identification/pa2.0_test/runs/dh99x6il</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6/207 00:36 < 30:55, 0.11 it/s, Epoch 0.07/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'elements', 'inputs', 'label_ids', 'losses', 'predictions']\n",
      "[[-0.02657874 -0.00130824 -0.02274894 ...  0.0340507   0.03407391\n",
      "   0.0021182 ]\n",
      " [-0.02286101 -0.00140207 -0.02168455 ...  0.03382852  0.0376953\n",
      "   0.00341862]\n",
      " [-0.03119706 -0.00026888 -0.02248574 ...  0.02992187  0.02957861\n",
      "  -0.00014747]\n",
      " ...\n",
      " [-0.02341311 -0.00152981 -0.02214546 ...  0.03451791  0.03754333\n",
      "   0.00336091]\n",
      " [-0.02381277 -0.00093005 -0.02129038 ...  0.03444204  0.03686347\n",
      "   0.00285016]\n",
      " [-0.02972663 -0.00155433 -0.02137574 ...  0.03372331  0.03247725\n",
      "   0.00017915]] (array([[[[0.4627451 , 0.49019608, 0.25882354, ..., 0.2901961 ,\n",
      "          0.1882353 , 0.22352941],\n",
      "         [0.42745098, 0.3137255 , 0.10588235, ..., 0.10980392,\n",
      "          0.04313726, 0.02352941],\n",
      "         [0.28235295, 0.12156863, 0.02745098, ..., 0.05490196,\n",
      "          0.05882353, 0.04313726],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.8039216 , 0.7921569 , 0.65882355, ..., 0.8862745 ,\n",
      "          0.5019608 , 0.91764706],\n",
      "         [0.4745098 , 0.84313726, 0.3137255 , ..., 0.92156863,\n",
      "          0.6431373 , 0.19607843],\n",
      "         [0.20784314, 0.654902  , 0.39215687, ..., 0.58431375,\n",
      "          0.7176471 , 0.16470589],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.07450981, 0.09411765, 0.01176471, ..., 0.00392157,\n",
      "          0.00392157, 0.00784314],\n",
      "         [0.10980392, 0.12156863, 0.01568628, ..., 0.        ,\n",
      "          0.01568628, 0.03137255],\n",
      "         [0.03137255, 0.02352941, 0.01176471, ..., 0.        ,\n",
      "          0.01568628, 0.02745098],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.00392157,\n",
      "          0.00392157, 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.00392157, 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]]],\n",
      "      shape=(128, 1, 128, 216), dtype=float32), array([[[[0.4627451 , 0.49019608, 0.25882354, ..., 0.2901961 ,\n",
      "          0.1882353 , 0.22352941],\n",
      "         [0.42745098, 0.3137255 , 0.10588235, ..., 0.10980392,\n",
      "          0.04313726, 0.02352941],\n",
      "         [0.28235295, 0.12156863, 0.02745098, ..., 0.05490196,\n",
      "          0.05882353, 0.04313726],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.8039216 , 0.7921569 , 0.65882355, ..., 0.8862745 ,\n",
      "          0.5019608 , 0.91764706],\n",
      "         [0.4745098 , 0.84313726, 0.3137255 , ..., 0.92156863,\n",
      "          0.6431373 , 0.19607843],\n",
      "         [0.20784314, 0.654902  , 0.39215687, ..., 0.58431375,\n",
      "          0.7176471 , 0.16470589],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.07450981, 0.09411765, 0.01176471, ..., 0.00392157,\n",
      "          0.00392157, 0.00784314],\n",
      "         [0.10980392, 0.12156863, 0.01568628, ..., 0.        ,\n",
      "          0.01568628, 0.03137255],\n",
      "         [0.03137255, 0.02352941, 0.01176471, ..., 0.        ,\n",
      "          0.01568628, 0.02745098],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.00392157,\n",
      "          0.00392157, 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.00392157, 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]]],\n",
      "      shape=(128, 1, 128, 216), dtype=float32), array([ 3, 19, 20,  9, 14, 20,  6, 18,  7,  6,  3,  3,  7,  1, 11, 13, 18,\n",
      "       20,  2, 13, 20, 16,  2, 14,  5, 18, 13, 12, 12, 13, 15,  3, 18, 13,\n",
      "       11, 13, 11,  6, 14, 13, 10,  6, 14, 16, 13,  6, 18,  6,  9, 12,  1,\n",
      "       14,  6, 20, 19,  6, 19, 19, 11, 11, 20, 11, 11, 11,  3,  4,  2,  6,\n",
      "       12,  9, 13, 11, 11, 11, 18, 14,  2, 15, 11, 13,  0,  1, 16,  6,  1,\n",
      "       13,  6, 19, 19,  7, 11, 12,  6, 11, 19,  4, 12, 20, 13,  2, 13,  8,\n",
      "       13, 11, 12, 11, 16, 10,  0,  7, 18, 10, 16, 10, 20,  8, 13, 17, 20,\n",
      "        3,  6, 11,  7, 20, 11, 19, 19, 11])) <class 'tuple'> 3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m trainer = PyhaTrainer(\n\u001b[32m      2\u001b[39m     model=model,\n\u001b[32m      3\u001b[39m     dataset=hsn_ads,\n\u001b[32m      4\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/transformers/trainer.py:2627\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2625\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m + steps_skipped) / steps_in_epoch\n\u001b[32m   2626\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2627\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2638\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/transformers/trainer.py:3096\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3094\u001b[39m metrics = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_evaluate:\n\u001b[32m-> \u001b[39m\u001b[32m3096\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3097\u001b[39m     is_new_best_metric = \u001b[38;5;28mself\u001b[39m._determine_best_metric(metrics=metrics, trial=trial)\n\u001b[32m   3099\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_strategy == SaveStrategy.BEST:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/transformers/trainer.py:3045\u001b[39m, in \u001b[36mTrainer._evaluate\u001b[39m\u001b[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[39m\n\u001b[32m   3044\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m3045\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3046\u001b[39m     \u001b[38;5;28mself\u001b[39m._report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m.state.global_step, metrics)\n\u001b[32m   3048\u001b[39m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/pyha_analyzer/trainer.py:82\u001b[39m, in \u001b[36mPyhaTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ignore_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m#is this the best place for this?\u001b[39;00m\n\u001b[32m     79\u001b[39m     \u001b[38;5;66;03m# there maybe a training_arg that defines this by default. Should be changed there...\u001b[39;00m\n\u001b[32m     80\u001b[39m     ignore_keys = [\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m] \n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/transformers/trainer.py:4154\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4151\u001b[39m start_time = time.time()\n\u001b[32m   4153\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4154\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4155\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[32m   4159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4162\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4164\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/transformers/trainer.py:4444\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4442\u001b[39m     eval_set_kwargs[\u001b[33m\"\u001b[39m\u001b[33mlosses\u001b[39m\u001b[33m\"\u001b[39m] = all_losses \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4443\u001b[39m     eval_set_kwargs[\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m] = all_inputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4444\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43meval_set_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4446\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4447\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4448\u001b[39m     metrics = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/pyha_analyzer/metrics/evaluate.py:55\u001b[39m, in \u001b[36mComputeMetricsBase.__call__\u001b[39m\u001b[34m(self, eval_pred)\u001b[39m\n\u001b[32m     53\u001b[39m result = {}\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metric_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metrics_to_run.keys():\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     result[metric_name] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetrics_to_run\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/pyha_analyzer/metrics/classification_metrics.py:31\u001b[39m, in \u001b[36mcMAP.__call__\u001b[39m\u001b[34m(self, logits, target)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, logits=[], target=[]) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     map_by_class = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     cmap = map_by_class.nanmean()\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m#TODO FIX This to define weight based on number of targets per class in batch\u001b[39;00m\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m#smap = (map_by_class * class_dist/class_dist.sum()).nansum() \u001b[39;00m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# https://forums.fast.ai/t/nan-values-when-using-precision-in-multi-classification/59767/2\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# Could be possible when model is untrained so we only have FNs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/torchmetrics/metric.py:315\u001b[39m, in \u001b[36mMetric.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    313\u001b[39m     \u001b[38;5;28mself\u001b[39m._forward_cache = \u001b[38;5;28mself\u001b[39m._forward_full_state_update(*args, **kwargs)\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     \u001b[38;5;28mself\u001b[39m._forward_cache = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_cache\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/torchmetrics/metric.py:384\u001b[39m, in \u001b[36mMetric._forward_reduce_state_update\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;28mself\u001b[39m._enable_grad = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[32m    383\u001b[39m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    385\u001b[39m batch_val = \u001b[38;5;28mself\u001b[39m.compute()\n\u001b[32m    387\u001b[39m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/torchmetrics/metric.py:549\u001b[39m, in \u001b[36mMetric._wrap_update.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m._enable_grad):\n\u001b[32m    548\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    551\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected all tensors to be on\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/torchmetrics/classification/precision_recall_curve.py:364\u001b[39m, in \u001b[36mMulticlassPrecisionRecallCurve.update\u001b[39m\u001b[34m(self, preds, target)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Update metric states.\"\"\"\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.validate_args:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     \u001b[43m_multiclass_precision_recall_curve_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m preds, target, _ = _multiclass_precision_recall_curve_format(\n\u001b[32m    366\u001b[39m     preds, target, \u001b[38;5;28mself\u001b[39m.num_classes, \u001b[38;5;28mself\u001b[39m.thresholds, \u001b[38;5;28mself\u001b[39m.ignore_index, \u001b[38;5;28mself\u001b[39m.average\n\u001b[32m    367\u001b[39m )\n\u001b[32m    368\u001b[39m state = _multiclass_precision_recall_curve_update(\n\u001b[32m    369\u001b[39m     preds, target, \u001b[38;5;28mself\u001b[39m.num_classes, \u001b[38;5;28mself\u001b[39m.thresholds, \u001b[38;5;28mself\u001b[39m.average\n\u001b[32m    370\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pyha-analyzer-2.0/.venv/lib/python3.11/site-packages/torchmetrics/functional/classification/precision_recall_curve.py:399\u001b[39m, in \u001b[36m_multiclass_precision_recall_curve_tensor_validation\u001b[39m\u001b[34m(preds, target, num_classes, ignore_index)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_multiclass_precision_recall_curve_tensor_validation\u001b[39m(\n\u001b[32m    390\u001b[39m     preds: Tensor, target: Tensor, num_classes: \u001b[38;5;28mint\u001b[39m, ignore_index: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    391\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    392\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate tensor input.\u001b[39;00m\n\u001b[32m    393\u001b[39m \n\u001b[32m    394\u001b[39m \u001b[33;03m    - target should have one more dimension than preds and all dimensions except for preds.shape[1] should match\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m \n\u001b[32m    398\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m preds.ndim == \u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m + \u001b[32m1\u001b[39m:\n\u001b[32m    400\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    401\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected `preds` to have one more dimension than `target` but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreds.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    402\u001b[39m         )\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m target.is_floating_point():\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "trainer = PyhaTrainer(\n",
    "    model=model,\n",
    "    dataset=hsn_ads,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38eb82",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
